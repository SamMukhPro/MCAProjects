{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamMukhPro/MCAProjects/blob/main/Major_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC_0uxmFgvpM"
      },
      "source": [
        "**FILE UPLOAD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "8TMCh1U1CCrZ",
        "outputId": "cc6dec99-5423-447a-c479-8e3c6b65d200"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88432e17-1396-4e75-8736-137177f66263\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88432e17-1396-4e75-8736-137177f66263\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Untitled document.txt to Untitled document.txt\n",
            "তরুণের বিদ্রোহবন্ধুগণ,নিজের জীবন এলো যখন সমাপ্তির দিকে, তখন ডাক পড়লো আমার দেশের এই যৌবন-শক্তিকে সম্বোধন ক’রে তাদের যাত্রাপথের সন্ধান দিতে। নিজের মধ্যে কর্মশক্তি যখন নিঃশেষিতপ্রায়, উদ্যম ক্লান্ত, প্রেরণা ক্ষীণ, তখন তরুণের অপরিমেয় প্রাণধারার দিক-নির্ণয়ের ভার পড়লো এক বৃদ্ধের উপর। এ আহ্বানে সাড়া দিবার শক্তি-সামর্থ্য নেই—সময় গেছে। এ আহানে বুকের মধ্যে শুধু বেদনার সঞ্চার করে।\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnchhXMChGVj"
      },
      "source": [
        "**(B) LANGUAGE-SPECIFIC FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMGcbWqkCS4B",
        "outputId": "156c0657-3c15-4085-f6b1-83ef791cb82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Results ---\n",
            "Filename: Untitled document.txt\n",
            "Total_Juktakkhor (AJuk): 24\n",
            "Avg_per_Sentence (JUK): 6.0\n",
            "Samples_Found: ['দ্র', 'ন্ধ', 'প্ত', 'ক্ত', 'ম্ব', 'ত্র', 'ন্ধ', 'ধ্য', 'র্ম', 'ক্ত', 'প্র', 'দ্য', 'ক্ল', 'ন্ত', 'প্র', 'ক্ষ', 'প্র', 'র্ণ', 'দ্ধ', 'হ্ব', 'ক্ত', 'র্থ্য', 'ধ্য', 'ঞ্চ']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def extract_juktakkhor_features(text,filename):\n",
        "    # Regex for Bengali Consonant range\n",
        "    # \\u0985 to \\u09B9 covers the main Bengali alphabet\n",
        "    consonant = r'[\\u0985-\\u09B9]'\n",
        "    hasanta = r'\\u09CD'\n",
        "\n",
        "    # Detect 2+ consonant conjunct clusters\n",
        "    juktakkhor_pattern = f'{consonant}(?:{hasanta}{consonant})+'\n",
        "\n",
        "    # 3. Find all true Juktakkhors\n",
        "    all_juks = re.findall(juktakkhor_pattern, text)\n",
        "    total_juks = len(all_juks)\n",
        "\n",
        "    # 4. Count sentences (splitting by Dari, Question mark, or Exclamation)\n",
        "    sentences = re.split(r'[।!?]', text)\n",
        "    # Filter out empty strings from the list\n",
        "    sentences = [s for s in sentences if s.strip()]\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    # 5. Calculate AJuk (Total) and JUK (Average)\n",
        "    ajuk = total_juks\n",
        "    juk_per_sentence = total_juks / num_sentences if num_sentences > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"Filename\": filename,\n",
        "        \"Total_Juktakkhor (AJuk)\": ajuk,\n",
        "        \"Avg_per_Sentence (JUK)\": round(juk_per_sentence, 3),\n",
        "        \"Samples_Found\": all_juks  # Shows the first 10 for verification\n",
        "    }\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"\\n--- Processing Results ---\")\n",
        "results = extract_juktakkhor_features(text,filename)\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNQChKwz_G-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2bc54f-47cf-49be-9a95-5ef3edf2924c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.12/dist-packages (0.92)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.3)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.4)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (4.1.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (26.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2026.1.4)\n",
            "Requirement already satisfied: roman-numerals==4.1.0 in /usr/local/lib/python3.12/dist-packages (from roman-numerals-py>=1.0.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (4.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install indic-nlp-library nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-0U3b9AHKx1",
        "outputId": "30a36f68-7775-4066-c0f8-3751b0ad4900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126 (from 1)\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 28.69 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-APUJOUHvek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "D8BBCnVkF2Ba",
        "outputId": "9cf50cd5-a8dd-4ff0-b4c1-9a7fbde810bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'indicnlp.common' has no attribute 'get_stopwords'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-905392122.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get Bengali (bn) stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbn_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Count stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'indicnlp.common' has no attribute 'get_stopwords'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VZJGApG_Xk_",
        "outputId": "f0ec2149-8fb6-4d79-ff73-741757a1b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AduAS94LBWhJ"
      },
      "source": [
        "**SHALLOW/LEXICAL FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsXNlNy3_ggF"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# Bengali Readability – Shallow / Lexical Features\n",
        "# ===============================================\n",
        "\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Bengali linguistic resources\n",
        "# -----------------------------------------------\n",
        "\n",
        "BENGALI_VOWELS = set(\"অআইঈউঊঋএঐওঔািীুূৃেৈোৌ\")\n",
        "\n",
        "BENGALI_STOPWORDS = {\n",
        "    \"ও\",\"এবং\",\"যে\",\"এই\",\"তার\",\"একটি\",\"হয়\",\"ছিল\",\"করে\",\"কে\",\n",
        "    \"আমি\",\"তুমি\",\"সে\",\"আমরা\",\"তারা\",\"এর\",\"না\",\"থেকে\",\"মধ্যে\"\n",
        "}\n",
        "\n",
        "BENGALI_PREFIXES = (\"অ\",\"অন\",\"প্র\",\"উপ\",\"বি\",\"নি\",\"সম\",\"পরি\",\"অতি\")\n",
        "BENGALI_SUFFIXES = (\"তা\",\"ত্ব\",\"কারী\",\"করণ\",\"ভাবে\",\"গুলি\",\"দের\",\"দেরকে\")\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Helper functions\n",
        "# -----------------------------------------------\n",
        "\n",
        "def count_syllables(word):\n",
        "    return sum(1 for ch in word if ch in BENGALI_VOWELS)\n",
        "\n",
        "def count_affixes(word):\n",
        "    count = 0\n",
        "    for p in BENGALI_PREFIXES:\n",
        "        if word.startswith(p) and len(word) > len(p):\n",
        "            count += 1\n",
        "    for s in BENGALI_SUFFIXES:\n",
        "        if word.endswith(s) and len(word) > len(s):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# -----------------------------------------------\n",
        "# MAIN FEATURE EXTRACTION\n",
        "# -----------------------------------------------\n",
        "\n",
        "def extract_bengali_features(text):\n",
        "\n",
        "    # Normalize Bengali text\n",
        "    normalizer = IndicNormalizerFactory().get_normalizer(\"bn\")\n",
        "    text = normalizer.normalize(text)\n",
        "\n",
        "    # Sentence split\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    num_sentences = len(sentences)\n",
        "\n",
        "    # Word tokenize (Indic NLP)\n",
        "    words = indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "    # Keep Bengali words only\n",
        "    words = [w for w in words if re.fullmatch(r\"[\\u0980-\\u09FF]+\", w)]\n",
        "\n",
        "    total_words = len(words)\n",
        "    if total_words == 0:\n",
        "        return {}\n",
        "\n",
        "    # Feature counters\n",
        "    char_lengths = [len(w) for w in words]\n",
        "    syllables = [count_syllables(w) for w in words]\n",
        "\n",
        "    six_char_words = sum(1 for l in char_lengths if l >= 6)\n",
        "    monosyllabic_words = sum(1 for s in syllables if s == 1)\n",
        "    polysyllabic_words = sum(1 for s in syllables if s >= 3)\n",
        "\n",
        "    total_syllables = sum(syllables)\n",
        "    affix_count = sum(count_affixes(w) for w in words)\n",
        "    stopword_count = sum(1 for w in words if w in BENGALI_STOPWORDS)\n",
        "\n",
        "    # Averages\n",
        "    avg_sentence_length = total_words / num_sentences\n",
        "    avg_word_length = sum(char_lengths) / total_words\n",
        "    avg_syllables_per_word = total_syllables / total_words\n",
        "    polysyllables_per_sentence = polysyllabic_words / num_sentences\n",
        "\n",
        "    return {\n",
        "        \"1. Word_Lengths_(characters)\": char_lengths,\n",
        "        \"2. Words_>=6_Characters\": six_char_words,\n",
        "        \"3. Total_Syllables\": total_syllables,\n",
        "        \"4. Monosyllabic_Words\": monosyllabic_words,\n",
        "        \"5. Words_>=3_Syllables\": polysyllabic_words,\n",
        "        \"6. Number_of_Affixes\": affix_count,\n",
        "        \"7. Average_Sentence_Length\": round(avg_sentence_length, 3),\n",
        "        \"8. Average_Word_Length\": round(avg_word_length, 3),\n",
        "        \"9. Polysyllabic_Words_per_Sentence\": round(polysyllables_per_sentence, 3),\n",
        "        \"10. Average_Syllables_per_Word\": round(avg_syllables_per_word, 3),\n",
        "        \"11. Stopwords_per_Document\": stopword_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FtdO0PjAiDW",
        "outputId": "6598a7da-f824-4f58-bba6-33c275bc1121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bengali Shallow / Lexical Features:\n",
            "\n",
            "1. Word_Lengths_(characters): [6, 14, 5, 4, 3, 3, 8, 4, 3, 3, 5, 4, 5, 2, 4, 7, 7, 1, 2, 5, 10, 6, 4, 5, 5, 9, 3, 14, 5, 7, 7, 5, 3, 6, 8, 10, 3, 9, 3, 5, 2, 7, 3, 1, 7, 5, 5, 5, 8, 3, 4, 4, 1, 5, 5, 5, 4, 6, 6, 3]\n",
            "2. Words_>=6_Characters: 20\n",
            "3. Total_Syllables: 92\n",
            "4. Monosyllabic_Words: 24\n",
            "5. Words_>=3_Syllables: 7\n",
            "6. Number_of_Affixes: 13\n",
            "7. Average_Sentence_Length: 60.0\n",
            "8. Average_Word_Length: 5.183\n",
            "9. Polysyllabic_Words_per_Sentence: 7.0\n",
            "10. Average_Syllables_per_Word: 1.533\n",
            "11. Stopwords_per_Document: 4\n"
          ]
        }
      ],
      "source": [
        "features = extract_bengali_features(text)\n",
        "\n",
        "print(\"\\nBengali Shallow / Lexical Features:\\n\")\n",
        "for k, v in features.items():\n",
        "    print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ufal.udpipe indic-nlp-library\n"
      ],
      "metadata": {
        "id": "XbUj-Ume3oGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11dca10-f8bb-4c46-c1ab-425a11d6ca54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download from LINDAT/CLARIN official model repository\n",
        "!wget -O /content/bengali-ud-2.17-251125.udpipe \\\n",
        "\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11858/00-297C-0000-0029-0A34-2/bengali-ud-2.17-251125.udpipe?sequence=1&isAllowed=y\"\n",
        "\n",
        "# List to verify\n",
        "!ls -lh /content/bengali-ud-2.17-251125.udpipe\n"
      ],
      "metadata": {
        "id": "GRvhHf3h3r_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c4d0f9-e38f-4bdf-891f-81e13fac5852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-16 15:49:39--  https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11858/00-297C-0000-0029-0A34-2/bengali-ud-2.17-251125.udpipe?sequence=1&isAllowed=y\n",
            "Resolving lindat.mff.cuni.cz (lindat.mff.cuni.cz)... 195.113.20.140\n",
            "Connecting to lindat.mff.cuni.cz (lindat.mff.cuni.cz)|195.113.20.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://lindat.mff.cuni.cz/repository/bitstream/handle/11858/00-297C-0000-0029-0A34-2/bengali-ud-2.17-251125.udpipe?sequence=1&isAllowed=y [following]\n",
            "--2026-02-16 15:49:40--  https://lindat.mff.cuni.cz/repository/bitstream/handle/11858/00-297C-0000-0029-0A34-2/bengali-ud-2.17-251125.udpipe?sequence=1&isAllowed=y\n",
            "Reusing existing connection to lindat.mff.cuni.cz:443.\n",
            "HTTP request sent, awaiting response... 404 Not found\n",
            "2026-02-16 15:49:41 ERROR 404: Not found.\n",
            "\n",
            "-rw-r--r-- 1 root root 0 Feb 16 15:49 /content/bengali-ud-2.17-251125.udpipe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ufal.udpipe as udpipe\n",
        "import os\n",
        "\n",
        "MODEL_PATH = \"/content/bengali-ud-2.17-251125.udpipe\"\n",
        "\n",
        "assert os.path.exists(MODEL_PATH), \"❌ Model not found. Check the download cell.\"\n",
        "\n",
        "def load_udpipe_pipeline():\n",
        "    model = udpipe.Model.load(MODEL_PATH)\n",
        "    if model is None:\n",
        "        raise RuntimeError(\"Failed to load UDPipe model\")\n",
        "\n",
        "    pipeline = udpipe.Pipeline(\n",
        "        model,\n",
        "        \"tokenize\",\n",
        "        \"tag\",\n",
        "        \"parse\",\n",
        "        \"conllu\"\n",
        "    )\n",
        "    print(\"✅ UDPipe Bengali pipeline ready\")\n",
        "    return pipeline\n",
        "\n",
        "pipeline = load_udpipe_pipeline()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "_fYGkxjVHPCU",
        "outputId": "45abec61-4232-46e5-f24f-3c5fe3894121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to load UDPipe model",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2291632802.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_udpipe_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2291632802.py\u001b[0m in \u001b[0;36mload_udpipe_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to load UDPipe model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     pipeline = udpipe.Pipeline(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to load UDPipe model"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ufal.udpipe as udpipe\n",
        "\n",
        "model = udpipe.Model.load(\"bengali-bdt-ud-2.5-191206.udpipe\")\n",
        "\n",
        "pipeline = udpipe.Pipeline(\n",
        "    model,\n",
        "    \"tokenize\",\n",
        "    udpipe.Pipeline.DEFAULT,\n",
        "    udpipe.Pipeline.DEFAULT,\n",
        "    \"conllu\"\n",
        ")\n",
        "\n",
        "print(\"✅ UDPipe Bengali pipeline ready\")\n",
        "\n",
        "pipeline = load_udpipe_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "eU2sUTZH3vMs",
        "outputId": "01ed1132-a7af-475e-fc8c-eb3dfcb8da88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ UDPipe Bengali pipeline ready\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "UDPipe Bengali model not found at /content/bengali-bdt-ud-2.5-191206.udpipe",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1227965614.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ UDPipe Bengali pipeline ready\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_udpipe_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-693537616.py\u001b[0m in \u001b[0;36mload_udpipe_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_udpipe_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UDPipe Bengali model not found at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: UDPipe Bengali model not found at /content/bengali-bdt-ud-2.5-191206.udpipe"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "txt_files = [f for f in os.listdir('/content') if f.endswith('.txt')]\n",
        "filename = '/content/' + txt_files[-1]\n",
        "\n",
        "with open(filename, 'r', encoding='utf-8-sig') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"Loaded:\", filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c3FaW5h5sGY",
        "outputId": "ea66a844-8b3c-426a-f326-44d36e2a2c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/New Text Document (2) - Copy - Copy.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bengali_pos_features(text):\n",
        "\n",
        "    processed = pipeline.process(text)\n",
        "    lines = processed.split(\"\\n\")\n",
        "\n",
        "    counts = {\n",
        "        \"AJJ\": 0,\n",
        "        \"ANN\": 0,\n",
        "        \"ACC\": 0,\n",
        "        \"PRON\": 0,\n",
        "        \"ADV\": 0,\n",
        "        \"PART\": 0,\n",
        "        \"POS\": 0\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith(\"#\") or line.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        cols = line.split(\"\\t\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "\n",
        "        upos = cols[3]\n",
        "        counts[\"POS\"] += 1\n",
        "\n",
        "        if upos == \"ADJ\":\n",
        "            counts[\"AJJ\"] += 1\n",
        "        elif upos in [\"NOUN\", \"PROPN\"]:\n",
        "            counts[\"ANN\"] += 1\n",
        "        elif upos in [\"CCONJ\", \"SCONJ\"]:\n",
        "            counts[\"ACC\"] += 1\n",
        "        elif upos == \"PRON\":\n",
        "            counts[\"PRON\"] += 1\n",
        "        elif upos == \"ADV\":\n",
        "            counts[\"ADV\"] += 1\n",
        "        elif upos == \"PART\":\n",
        "            counts[\"PART\"] += 1\n",
        "\n",
        "    return counts\n"
      ],
      "metadata": {
        "id": "3n4QyINa32Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_features = extract_bengali_pos_features(text)\n",
        "\n",
        "print(\"\\nBengali POS Features:\\n\")\n",
        "for k, v in pos_features.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "hYLH1lNo37_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "d7b23496-29fd-4b86-cb1d-d04c7450e0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'extract_bengali_pos_features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4218059931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_bengali_pos_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBengali POS Features:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{k}: {v}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'extract_bengali_pos_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ddc75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d4071430-5ef5-4b3a-ab48-1c80be127fd3"
      },
      "source": [
        "import os\n",
        "import ufal.udpipe as udpipe\n",
        "\n",
        "# Ensure pipeline is defined (re-initialize if necessary)\n",
        "# This code is duplicated from eU2sUTZH3vMs to make this cell self-contained\n",
        "if 'pipeline' not in locals() or 'pipeline' not in globals():\n",
        "    try:\n",
        "        model = udpipe.Model.load(\"bengali-bdt-ud-2.5-191206.udpipe\")\n",
        "        pipeline = udpipe.Pipeline(\n",
        "            model,\n",
        "            \"tokenize\",\n",
        "            udpipe.Pipeline.DEFAULT,\n",
        "            udpipe.Pipeline.DEFAULT,\n",
        "            \"conllu\"\n",
        "        )\n",
        "        print(\"✅ UDPipe Bengali pipeline re-initialized for this cell\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing pipeline: {e}\")\n",
        "        pipeline = None # Set to None if initialization fails\n",
        "\n",
        "\n",
        "# Ensure 'text' is defined by reloading the content from the last loaded file\n",
        "txt_files = [f for f in os.listdir('/content') if f.endswith('.txt')]\n",
        "if txt_files:\n",
        "    filename_to_load = '/content/' + txt_files[-1]\n",
        "    with open(filename_to_load, 'r', encoding='utf-8-sig') as f:\n",
        "        text = f.read()\n",
        "    print(f\"Reloaded text from: {filename_to_load}\")\n",
        "else:\n",
        "    print(\"No text files found in /content/ to reload.\")\n",
        "\n",
        "# Now, execute the feature extraction if pipeline is successfully initialized\n",
        "if pipeline:\n",
        "    pos_features = extract_bengali_pos_features(text)\n",
        "\n",
        "    print(\"\\nBengali POS Features:\\n\")\n",
        "    for k, v in pos_features.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"Cannot extract POS features: UDPipe pipeline failed to initialize.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ufal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3813366525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mufal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudpipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mudpipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ensure pipeline is defined (re-initialize if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This code is duplicated from eU2sUTZH3vMs to make this cell self-contained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ufal'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile bengali_pos_helper.py\n",
        "import os\n",
        "import ufal.udpipe as udpipe\n",
        "\n",
        "MODEL_PATH = \"bengali-bdt-ud-2.5-191206.udpipe\"\n",
        "\n",
        "def load_udpipe_pipeline():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        raise FileNotFoundError(\"UDPipe Bengali model not found\")\n",
        "\n",
        "    model = udpipe.Model.load(MODEL_PATH)\n",
        "    if model is None:\n",
        "        raise RuntimeError(\"Model failed to load\")\n",
        "\n",
        "    return udpipe.Pipeline(\n",
        "        model,\n",
        "        \"tokenize\",\n",
        "        \"tag\",\n",
        "        \"parse\",\n",
        "        \"conllu\"\n",
        "    )\n",
        "\n",
        "PIPELINE = load_udpipe_pipeline()\n",
        "\n",
        "def extract_bengali_pos_features(text):\n",
        "    processed = PIPELINE.process(text)\n",
        "    lines = processed.split(\"\\n\")\n",
        "\n",
        "    counts = {\n",
        "        \"AJJ\": 0,\n",
        "        \"ANN\": 0,\n",
        "        \"ACC\": 0,\n",
        "        \"PRON\": 0,\n",
        "        \"ADV\": 0,\n",
        "        \"PART\": 0,\n",
        "        \"POS\": 0\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        if not line or line.startswith(\"#\"):\n",
        "            continue\n",
        "        cols = line.split(\"\\t\")\n",
        "        if len(cols) < 4:\n",
        "            continue\n",
        "\n",
        "        upos = cols[3]\n",
        "        counts[\"POS\"] += 1\n",
        "\n",
        "        if upos == \"ADJ\":\n",
        "            counts[\"AJJ\"] += 1\n",
        "        elif upos in (\"NOUN\", \"PROPN\"):\n",
        "            counts[\"ANN\"] += 1\n",
        "        elif upos in (\"CCONJ\", \"SCONJ\"):\n",
        "            counts[\"ACC\"] += 1\n",
        "        elif upos == \"PRON\":\n",
        "            counts[\"PRON\"] += 1\n",
        "        elif upos == \"ADV\":\n",
        "            counts[\"ADV\"] += 1\n",
        "        elif upos == \"PART\":\n",
        "            counts[\"PART\"] += 1\n",
        "\n",
        "    return counts"
      ],
      "metadata": {
        "id": "-vabeE913COd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f58e566-3f04-4714-90c4-87c643434399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing bengali_pos_helper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"bengali-bdt-ud-2.5-191206.udpipe\")"
      ],
      "metadata": {
        "id": "q65Z0de5AiJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ufal.udpipe indic-nlp-library\n",
        "!wget -q https://raw.githubusercontent.com/UniversalDependencies/UD_Bengali-BDT/master/models/bengali-bdt-ud-2.5-191206.udpipe\n",
        "print(\"✅ Libraries installed and model downloaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GydCn0G4EO-b",
        "outputId": "ea7a1ede-ed2e-4bb1-e3d0-01c16654cdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries installed and model downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ufal.udpipe as udpipe\n",
        "import os\n",
        "\n",
        "MODEL_PATH = \"/content/bengali-bdt-ud-2.5-191206.udpipe\"\n",
        "\n"
      ],
      "metadata": {
        "id": "JDh4lsnTCePm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_udpipe_pipeline():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        raise FileNotFoundError(\"UDPipe Bengali model not found at \" + MODEL_PATH)\n",
        "\n",
        "    model = udpipe.Model.load(MODEL_PATH)\n",
        "    if model is None:\n",
        "        raise RuntimeError(\"Failed to load UDPipe model\")\n",
        "\n",
        "    pipeline = udpipe.Pipeline(\n",
        "        model,\n",
        "        \"tokenize\",\n",
        "        \"tag\",\n",
        "        \"parse\",\n",
        "        \"conllu\"\n",
        "    )\n",
        "    print(\"✅ UDPipe Bengali pipeline ready\")\n",
        "    return pipeline\n",
        "\n",
        "pipeline = load_udpipe_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "sy_MbkK1DTk6",
        "outputId": "e32f8e50-1d77-40c7-e2ce-9f6d9e881657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "UDPipe Bengali model not found at /content/bengali-bdt-ud-2.5-191206.udpipe",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-693537616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_udpipe_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-693537616.py\u001b[0m in \u001b[0;36mload_udpipe_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_udpipe_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UDPipe Bengali model not found at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: UDPipe Bengali model not found at /content/bengali-bdt-ud-2.5-191206.udpipe"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bnltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNtQ1wQZS4Tg",
        "outputId": "a4837771-6fe6-40cc-ab16-024378c69558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnltk in /usr/local/lib/python3.12/dist-packages (0.7.8)\n",
            "Requirement already satisfied: black==24.10.0 in /usr/local/lib/python3.12/dist-packages (from bnltk) (24.10.0)\n",
            "Requirement already satisfied: keras==3.6.0 in /usr/local/lib/python3.12/dist-packages (from bnltk) (3.6.0)\n",
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (from bnltk) (2.0.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.12/dist-packages (from bnltk) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn==1.5.2 in /usr/local/lib/python3.12/dist-packages (from bnltk) (1.5.2)\n",
            "Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.12/dist-packages (from bnltk) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black==24.10.0->bnltk) (8.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from black==24.10.0->bnltk) (1.1.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from black==24.10.0->bnltk) (26.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from black==24.10.0->bnltk) (1.0.4)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black==24.10.0->bnltk) (4.5.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras==3.6.0->bnltk) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.3->bnltk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.3->bnltk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.3->bnltk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.3->bnltk) (2026.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.2->bnltk) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.2->bnltk) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.2->bnltk) (3.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (5.29.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (1.76.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0->bnltk) (2.18.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0->bnltk) (0.46.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->bnltk) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->bnltk) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->bnltk) (3.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras==3.6.0->bnltk) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras==3.6.0->bnltk) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.6.0->bnltk) (0.1.2)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0->bnltk) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
        "import os\n",
        "\n",
        "print(\"✅ Indic NLP library ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saRl5ZsQS9TS",
        "outputId": "40bd3108-5e8d-4ae1-e7fd-c8358e5bdf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Indic NLP library ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files = [f for f in os.listdir(\"/content\") if f.endswith(\".txt\")]\n",
        "if not txt_files:\n",
        "    raise FileNotFoundError(\"💡 Upload a Bengali .txt file to /content first!\")\n",
        "\n",
        "filename = \"/content/\" + txt_files[-1]\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f\"✅ Loaded text from: {filename[:60]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDNjK0rmUB6O",
        "outputId": "178ba0a3-f605-443e-ea03-14b64a9bda6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded text from: /content/তরুণের বিদ্রোহ.txt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can expand these lists as needed\n",
        "ADJECTIVES = [\"ভালো\", \"মোটামুটি\", \"বড়\", \"ছোট\", \"নতুন\"]  # common Bengali adjectives\n",
        "NOUNS = [\"ছেলে\", \"মেয়ে\", \"বই\", \"বিদ্যালয়\", \"শিক্ষক\"]  # common nouns\n",
        "CONJUNCTIONS = [\"এবং\", \"কিন্তু\", \"অথবা\", \"যদি\"]  # common conjunctions\n",
        "PRONOUNS = [\"আমি\", \"তুমি\", \"সে\", \"আমরা\", \"তাদের\"]\n",
        "ADVERBS = [\"খুব\", \"ধীরে\", \"শিগগিরই\", \"ততক্ষণ\"]\n",
        "ARTICLES = [\"একটি\", \"এই\", \"সেটি\"]  # determiners / articles\n"
      ],
      "metadata": {
        "id": "6Dfv-r-yUOta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize Bengali text\n",
        "tokens = indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "counts = {\n",
        "    \"ADJ\": 0,\n",
        "    \"NOUN\": 0,\n",
        "    \"CONJ\": 0,\n",
        "    \"PRON\": 0,\n",
        "    \"ADV\": 0,\n",
        "    \"ART\": 0,\n",
        "    \"POS_TOTAL\": len(tokens)\n",
        "}\n",
        "\n",
        "for token in tokens:\n",
        "    if token in ADJECTIVES:\n",
        "        counts[\"ADJ\"] += 1\n",
        "    elif token in NOUNS:\n",
        "        counts[\"NOUN\"] += 1\n",
        "    elif token in CONJUNCTIONS:\n",
        "        counts[\"CONJ\"] += 1\n",
        "    elif token in PRONOUNS:\n",
        "        counts[\"PRON\"] += 1\n",
        "    elif token in ADVERBS:\n",
        "        counts[\"ADV\"] += 1\n",
        "    elif token in ARTICLES:\n",
        "        counts[\"ART\"] += 1\n"
      ],
      "metadata": {
        "id": "hptMyL8JUUiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n📊 Bengali POS Features (approximation using Indic NLP):\\n\")\n",
        "for k, v in counts.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPAjb4OcUcyL",
        "outputId": "4efc040a-684c-4d3d-e430-4fb5608cf650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Bengali POS Features (approximation using Indic NLP):\n",
            "\n",
            "ADJ: 12\n",
            "NOUN: 2\n",
            "CONJ: 60\n",
            "PRON: 65\n",
            "ADV: 2\n",
            "ART: 45\n",
            "POS_TOTAL: 3805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJXa8skHxPu",
        "outputId": "1cb42420-3237-494f-998b-ada3038201ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnlp-toolkit\n",
            "  Using cached bnlp_toolkit-4.4.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting sentencepiece==0.2.0 (from bnlp-toolkit)\n",
            "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting gensim==4.3.2 (from bnlp-toolkit)\n",
            "  Using cached gensim-4.3.2.tar.gz (23.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of bnlp-toolkit to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting bnlp-toolkit\n",
            "  Downloading bnlp_toolkit-4.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading bnlp_toolkit-4.2.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "  Downloading bnlp_toolkit-4.1.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "  Downloading bnlp_toolkit-4.0.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading bnlp_toolkit-4.0.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading bnlp_toolkit-4.0.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting nltk==3.8.1 (from bnlp-toolkit)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting bnlp-toolkit\n",
            "  Downloading bnlp_toolkit-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (0.2.1)\n",
            "Collecting gensim (from bnlp-toolkit)\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (1.16.3)\n",
            "Collecting sklearn-crfsuite (from bnlp-toolkit)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (4.67.3)\n",
            "Collecting ftfy (from bnlp-toolkit)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting emoji==1.7.0 (from bnlp-toolkit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bnlp-toolkit) (2.32.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->bnlp-toolkit) (0.5.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim->bnlp-toolkit) (7.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->bnlp-toolkit) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->bnlp-toolkit) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->bnlp-toolkit) (2025.11.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bnlp-toolkit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bnlp-toolkit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bnlp-toolkit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bnlp-toolkit) (2026.1.4)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->bnlp-toolkit)\n",
            "  Downloading python_crfsuite-0.9.12-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->bnlp-toolkit) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim->bnlp-toolkit) (2.1.1)\n",
            "Downloading bnlp_toolkit-4.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.12-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=b14efd57a783b8e49f776f531f8c8c61bea54600dec53e9799a0c290c4ff0c81\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8c/e0/294d2e4ea0e55792bfc99b6b263e4a0511443da7b69af67688\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, python-crfsuite, ftfy, gensim, sklearn-crfsuite, bnlp-toolkit\n",
            "Successfully installed bnlp-toolkit-4.0.0 emoji-1.7.0 ftfy-6.3.1 gensim-4.4.0 python-crfsuite-0.9.12 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "c3fHYon3IjUu",
        "outputId": "039270c8-0ad8-405f-e738-d88c5d6ae66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'stopwords' from 'bnlp.corpus' (/usr/local/lib/python3.12/dist-packages/bnlp/corpus/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1726459921.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbn_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Bengali stopwords:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'stopwords' from 'bnlp.corpus' (/usr/local/lib/python3.12/dist-packages/bnlp/corpus/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx7gpLmzfLqM",
        "outputId": "ea5e112f-aa90-4058-9a9c-4005fd7f7694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stopwordsiso\n",
            "  Using cached stopwordsiso-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading stopwordsiso-0.6.1-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stopwordsiso\n",
            "Successfully installed stopwordsiso-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stopwordsiso"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBJOl_66d0Yi",
        "outputId": "22112064-c6cb-4c50-d9f8-82294869c2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stopwordsiso\n",
            "  Downloading stopwordsiso-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading stopwordsiso-0.6.1-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m71.7/73.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stopwordsiso\n",
            "Successfully installed stopwordsiso-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stopwordsiso as stopwords\n",
        "\n",
        "bn_stopwords = list(stopwords.stopwords(\"bn\"))\n",
        "print(\"Total Bengali stopwords:\", len(bn_stopwords))\n",
        "\n",
        "\n",
        "print(*bn_stopwords, sep=\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-weS5Ejgqp5",
        "outputId": "2514dca6-03ff-48b9-c4dc-343cfd79cc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Bengali stopwords: 398\n",
            "অন্তত\n",
            "সেটা\n",
            "যাতে\n",
            "তবু\n",
            "দুই\n",
            "আগেই\n",
            "আমার\n",
            "এতটাই\n",
            "হয়\n",
            "তাতে\n",
            "হয়েছে\n",
            "করিয়া\n",
            "দিয়েছে\n",
            "যাওয়া\n",
            "কিছু\n",
            "এটাই\n",
            "পরেও\n",
            "দেখে\n",
            "উপরে\n",
            "সেটি\n",
            "অনেকেই\n",
            "আদ্যভাগে\n",
            "নেওয়া\n",
            "হত\n",
            "করতে\n",
            "ফিরে\n",
            "প্রাথমিক\n",
            "ক্ষেত্রে\n",
            "কেউই\n",
            "বেশি\n",
            "হয়ে\n",
            "চেষ্টা\n",
            "এই\n",
            "যা\n",
            "গেলে\n",
            "তখন\n",
            "কমনে\n",
            "জানিয়েছে\n",
            "কোনো\n",
            "যখন\n",
            "সেখান\n",
            "স্পষ্ট\n",
            "থেকেও\n",
            "হোক\n",
            "পারি\n",
            "যাদের\n",
            "এব\n",
            "কোটি\n",
            "ও\n",
            "দেন\n",
            "নেওয়ার\n",
            "এখনও\n",
            "এটি\n",
            "বিশেষ\n",
            "যার\n",
            "তো\n",
            "তারা\n",
            "উপর\n",
            "চলে\n",
            "জন\n",
            "বলেন\n",
            "দুটি\n",
            "হইয়া\n",
            "সবার\n",
            "অবধি\n",
            "নতুন\n",
            "থাকেন\n",
            "এদের\n",
            "মতো\n",
            "কেন\n",
            "গুলি\n",
            "হয়েই\n",
            "বদলে\n",
            "কাছ\n",
            "করেই\n",
            "ওদের\n",
            "ওখানে\n",
            "করিতে\n",
            "ওর\n",
            "র\n",
            "নয়\n",
            "এঁরা\n",
            "হলেও\n",
            "জনের\n",
            "সঙ্গেও\n",
            "ইহা\n",
            "বহু\n",
            "অবশ্য\n",
            "বলা\n",
            "তিনি\n",
            "যত\n",
            "যাকে\n",
            "এবং\n",
            "নাই\n",
            "কয়েকটি\n",
            "তারৈ\n",
            "ধরা\n",
            "সহ\n",
            "হতেই\n",
            "তবে\n",
            "তিনঐ\n",
            "কবে\n",
            "অতএব\n",
            "হৈলে\n",
            "রেখে\n",
            "আগামী\n",
            "এখানে\n",
            "থাকায়\n",
            "থাকা\n",
            "গিয়ে\n",
            "নিয়ে\n",
            "নানা\n",
            "থেকে\n",
            "করার\n",
            "যায়\n",
            "কে\n",
            "উত্তর\n",
            "ছাড়াও\n",
            "পারে\n",
            "বা\n",
            "কাছে\n",
            "এর\n",
            "বলেছেন\n",
            "চার\n",
            "এমনকী\n",
            "করেন\n",
            "হিসাবে\n",
            "আপনি\n",
            "পর্যন্ত\n",
            "রাখা\n",
            "এত\n",
            "হয়েছেন\n",
            "যারা\n",
            "মোটেই\n",
            "ওরা\n",
            "সেই\n",
            "থেকেই\n",
            "যান\n",
            "ধরে\n",
            "করা\n",
            "করলেন\n",
            "কী\n",
            "যাঁর\n",
            "দেখা\n",
            "প্রথম\n",
            "অন্য\n",
            "স্বয়ং\n",
            "ফের\n",
            "ছিলেন\n",
            "কাউকে\n",
            "পক্ষে\n",
            "করে\n",
            "নিয়ে\n",
            "আজ\n",
            "তাই\n",
            "ওঁর\n",
            "করি\n",
            "এতে\n",
            "পর\n",
            "কাজে\n",
            "পরেই\n",
            "যাচ্ছে\n",
            "কাজ\n",
            "থাকবেন\n",
            "চায়\n",
            "বরং\n",
            "পাচ\n",
            "ওকে\n",
            "করিয়ে\n",
            "যেতে\n",
            "ছাড়া\n",
            "হন\n",
            "হয়\n",
            "তথা\n",
            "হয়নি\n",
            "সম্প্রতি\n",
            "তিনিও\n",
            "দিলেন\n",
            "যদিও\n",
            "জন্য\n",
            "আমি\n",
            "গোটা\n",
            "অর্থাত\n",
            "মধ্যেও\n",
            "সাধারণ\n",
            "জানায়\n",
            "মধ্যে\n",
            "তুলে\n",
            "যেখানে\n",
            "হল\n",
            "হবেন\n",
            "ভাবেই\n",
            "এমন\n",
            "কত\n",
            "পরে\n",
            "উচিত\n",
            "আরও\n",
            "নাকি\n",
            "ফলে\n",
            "আছে\n",
            "না\n",
            "কোনও\n",
            "উনি\n",
            "ঠিক\n",
            "করেছে\n",
            "যাওয়ার\n",
            "কারণ\n",
            "সব\n",
            "যাঁরা\n",
            "তাহাতে\n",
            "কারও\n",
            "দিয়ে\n",
            "ই\n",
            "তোমার\n",
            "তাঁরা\n",
            "সেটাও\n",
            "করলে\n",
            "এল\n",
            "বসে\n",
            "তাহলে\n",
            "কোন\n",
            "ঐ\n",
            "নিজেদের\n",
            "কেউ\n",
            "প্রভৃতি\n",
            "পি\n",
            "দুটো\n",
            "তা\n",
            "এসে\n",
            "আমরা\n",
            "ভাবে\n",
            "হতে\n",
            "জানিয়ে\n",
            "যথেষ্ট\n",
            "ওঁরা\n",
            "প্রায়\n",
            "সমস্ত\n",
            "জনকে\n",
            "আবার\n",
            "জানা\n",
            "হইবে\n",
            "শুরু\n",
            "নেই\n",
            "দেওয়ার\n",
            "এটা\n",
            "আই\n",
            "ওঁদের\n",
            "মধ্যভাগে\n",
            "গেছে\n",
            "তাহা\n",
            "কি\n",
            "সেখানে\n",
            "একে\n",
            "দিন\n",
            "পাওয়া\n",
            "করেছিলেন\n",
            "একটি\n",
            "জন্যওজে\n",
            "সহিত\n",
            "ওই\n",
            "তাঁর\n",
            "মধ্যেই\n",
            "আপনার\n",
            "পেয়্র্\n",
            "নিতে\n",
            "যাওয়া\n",
            "যে\n",
            "কেখা\n",
            "তাদের\n",
            "সি\n",
            "কিংবা\n",
            "সেটাই\n",
            "দিয়েছেন\n",
            "মাত্র\n",
            "হয়েছিল\n",
            "জে\n",
            "কখনও\n",
            "করবে\n",
            "তাহার\n",
            "বাদে\n",
            "বললেন\n",
            "দেওয়া\n",
            "যেমন\n",
            "নাগাদ\n",
            "হয়তো\n",
            "করাই\n",
            "তাঁদের\n",
            "নয়\n",
            "আমাদের\n",
            "যাবে\n",
            "করবেন\n",
            "দেয়\n",
            "অনেকে\n",
            "তাঁকে\n",
            "হওয়ার\n",
            "হবে\n",
            "মনে\n",
            "অনুযায়ী\n",
            "এ\n",
            "মোট\n",
            "প্রতি\n",
            "এঁদের\n",
            "ইত্যাদি\n",
            "হলে\n",
            "কয়েক\n",
            "চালু\n",
            "টি\n",
            "তার\n",
            "পারেন\n",
            "খুব\n",
            "মাধ্যমে\n",
            "ব্যবহার\n",
            "নিজে\n",
            "শুধু\n",
            "বার\n",
            "আগে\n",
            "করছেন\n",
            "হলো\n",
            "সঙ্গে\n",
            "রকম\n",
            "বক্তব্য\n",
            "দু\n",
            "গেল\n",
            "অথচ\n",
            "হচ্ছে\n",
            "করেছেন\n",
            "করায়\n",
            "চেয়ে\n",
            "বিভিন্ন\n",
            "বলল\n",
            "জানতে\n",
            "অনেক\n",
            "দিকে\n",
            "দিতে\n",
            "বেশ\n",
            "গিয়েছে\n",
            "তাঁাহারা\n",
            "হলেই\n",
            "ব্যাপারে\n",
            "অথবা\n",
            "দেখতে\n",
            "হইতে\n",
            "বলে\n",
            "লক্ষ\n",
            "কিছুই\n",
            "এরা\n",
            "বি\n",
            "প্রযন্ত\n",
            "তাও\n",
            "বিষয়টি\n",
            "একবার\n",
            "এখন\n",
            "করছে\n",
            "জ্নজন\n",
            "চান\n",
            "তেমন\n",
            "প্রায়\n",
            "এস\n",
            "এক্\n",
            "বন\n",
            "যিনি\n",
            "হাজার\n",
            "ছিল\n",
            "কিন্তু\n",
            "তারপর\n",
            "এবার\n",
            "তত\n",
            "হওয়ায়\n",
            "আর\n",
            "সে\n",
            "থাকে\n",
            "তাকে\n",
            "এমনি\n",
            "বিনা\n",
            "রয়েছে\n",
            "মতোই\n",
            "ধামার\n",
            "পেয়ে\n",
            "জানানো\n",
            "বলতে\n",
            "এখানেই\n",
            "দ্বারা\n",
            "গিয়ে\n",
            "যেন\n",
            "যদি\n",
            "আমাকে\n",
            "তুমি\n",
            "সামনে\n",
            "যতটা\n",
            "থাকবে\n",
            "কয়েক\n",
            "একই\n",
            "হওয়া\n",
            "নিজেই\n",
            "দেওয়া\n",
            "নিজের\n",
            "নেওয়া\n",
            "সুতরাং\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}